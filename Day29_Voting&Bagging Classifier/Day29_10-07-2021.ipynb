{
 "cells": [
  {
   "attachments": {
    "download.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](logo.png)\n",
    "\n",
    "## Day Objectives\n",
    "# Voting Classifier\n",
    "- A Voting Classifier is a machine learning model\n",
    "- predicts an output (class) based on their highest probability of chosen class as the output.\n",
    "- Voting classifier is quite effective with good estimators & handles individual's limitations, ensemble methods can also participate.\n",
    "- It's used for both classification and regression\n",
    "- **Voting Classifier supports two types of votings**\n",
    "    - Hard Voting: the predicted output class is a class with the highest majority of votes\n",
    "        - the class which had the highest probability of being predicted by each of the classifiers\n",
    "    - Soft Voting : the output class is the prediction based on the average of probability given to that class\n",
    "\n",
    "![download.png](attachment:download.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard -Voting:\n",
    "\n",
    "algo1 - -apple\n",
    "algo2 - -apple\n",
    "algo3 - -apple\n",
    "algo4 - -banana\n",
    "\n",
    "output - -apple\n",
    "\n",
    "Soft -voting:\n",
    "\n",
    "sub -: -math,ph,che\n",
    "alg1 - -(80.5,97.6,68) - -82%\n",
    "alg2 - -(68.6,78.7,90.9) - -79.4%\n",
    "alg3 - -(69.8,98.8,90) - -86.2%\n",
    "\n",
    "output -alg3 - -86.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.03333333333333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(80.5+97.6+68)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(69.8+98.8+90)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}\n"
     ]
    }
   ],
   "source": [
    "print(digits)"
   ]
  },
  {
   "attachments": {
    "download%20%281%29.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download%20%281%29.png](attachment:download%20%281%29.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       "\n",
       "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       "1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       "1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       "1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       "1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       "\n",
       "      pixel_7_6  pixel_7_7  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           9.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1792        0.0        0.0  \n",
       "1793        0.0        0.0  \n",
       "1794        0.0        0.0  \n",
       "1795        0.0        0.0  \n",
       "1796        1.0        0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(digits.data,columns = digits.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0        0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1        0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2        0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3        0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4        0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "\n",
       "   pixel_7_7  Target  \n",
       "0        0.0       0  \n",
       "1        0.0       1  \n",
       "2        0.0       2  \n",
       "3        0.0       3  \n",
       "4        0.0       4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Target\"]=digits.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    183\n",
       "5    182\n",
       "1    182\n",
       "6    181\n",
       "4    181\n",
       "9    180\n",
       "7    179\n",
       "0    178\n",
       "2    177\n",
       "8    174\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn =KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =df[df.columns[: -1]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =df[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1,X2,y1,y2=train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred=knn.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.33333333333333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2,yPred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcls=RandomForestClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcls.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.77777777777779"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=rcls.predict(X2)\n",
    "accuracy_score(y2,y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision -Tree -accuracy_score : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc -accuracy_score : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcls=DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcls.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredicted  =dcls.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.33333333333333"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2,ypredicted)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"knn\",KNeighborsClassifier(n_neighbors=5)),\n",
    "    (\"rf\",RandomForestClassifier(n_estimators=20,max_depth=5)),\n",
    "    (\"svc\",SVC(kernel='rbf',probability=False)),\n",
    "     (\"DT\",DecisionTreeClassifier(max_depth=5)),\n",
    "     (\"Lr\",LogisticRegression())\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vclass =VotingClassifier(estimators=estimators,voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier()),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=5,\n",
       "                                                     n_estimators=20)),\n",
       "                             ('svc', SVC()),\n",
       "                             ('DT', DecisionTreeClassifier(max_depth=5)),\n",
       "                             ('Lr', LogisticRegression())])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lavan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier()),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=5,\n",
       "                                                     n_estimators=20)),\n",
       "                             ('svc', SVC()),\n",
       "                             ('DT', DecisionTreeClassifier(max_depth=5)),\n",
       "                             ('Lr', LogisticRegression())])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclass.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=vclass.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.88888888888889"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2,ypred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier() ('knn', KNeighborsClassifier())\n",
      "RandomForestClassifier(max_depth=5, n_estimators=20) ('rf', RandomForestClassifier(max_depth=5, n_estimators=20))\n",
      "SVC() ('svc', SVC())\n",
      "DecisionTreeClassifier(max_depth=5) ('DT', DecisionTreeClassifier(max_depth=5))\n",
      "LogisticRegression() ('Lr', LogisticRegression())\n"
     ]
    }
   ],
   "source": [
    "for est,name in zip(vclass.estimators_,vclass.estimators):\n",
    "    print(est,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KNeighborsClassifier(),\n",
       " RandomForestClassifier(max_depth=5, n_estimators=20),\n",
       " SVC(),\n",
       " DecisionTreeClassifier(max_depth=5),\n",
       " LogisticRegression()]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclass.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('knn', KNeighborsClassifier()),\n",
       " ('rf', RandomForestClassifier(max_depth=5, n_estimators=20)),\n",
       " ('svc', SVC()),\n",
       " ('DT', DecisionTreeClassifier(max_depth=5)),\n",
       " ('Lr', LogisticRegression())]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclass.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn 99.33333333333333 %\n",
      "rf 94.44444444444444 %\n",
      "svc 98.66666666666667 %\n",
      "DT 66.66666666666666 %\n",
      "Lr 97.33333333333334 %\n"
     ]
    }
   ],
   "source": [
    "for est,name in zip(vclass.estimators_,vclass.estimators):\n",
    "    print(name[0],est.score(X2,y2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# soft -Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vclass =VotingClassifier(estimators=estimators,voting=\"soft\",weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lavan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier()),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=5,\n",
       "                                                     n_estimators=20)),\n",
       "                             ('svc', SVC()),\n",
       "                             ('DT', DecisionTreeClassifier(max_depth=5)),\n",
       "                             ('Lr', LogisticRegression())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclass.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-6562a4800028>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mypredicted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'soft'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m             \u001b[0mmaj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'hard' voting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;34m\"\"\"Predict class probabilities for X in 'soft' voting.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[0m\u001b[0;32m    303\u001b[0m                          weights=self._weights_not_none)\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \"\"\"\n\u001b[1;32m--> 657\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    625\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    626\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "ypredicted=vclass.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on VotingClassifier in module sklearn.ensemble._voting object:\n",
      "\n",
      "class VotingClassifier(sklearn.base.ClassifierMixin, _BaseVoting)\n",
      " |  VotingClassifier(estimators, *, voting='hard', weights=None, n_jobs=None, flatten_transform=True, verbose=False)\n",
      " |  \n",
      " |  Soft Voting/Majority Rule classifier for unfitted estimators.\n",
      " |  \n",
      " |  .. versionadded:: 0.17\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <voting_classifier>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimators : list of (str, estimator) tuples\n",
      " |      Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones\n",
      " |      of those original estimators that will be stored in the class attribute\n",
      " |      ``self.estimators_``. An estimator can be set to ``'drop'``\n",
      " |      using ``set_params``.\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          ``'drop'`` is accepted.\n",
      " |  \n",
      " |      .. deprecated:: 0.22\n",
      " |         Using ``None`` to drop an estimator is deprecated in 0.22 and\n",
      " |         support will be dropped in 0.24. Use the string ``'drop'`` instead.\n",
      " |  \n",
      " |  voting : {'hard', 'soft'}, default='hard'\n",
      " |      If 'hard', uses predicted class labels for majority rule voting.\n",
      " |      Else if 'soft', predicts the class label based on the argmax of\n",
      " |      the sums of the predicted probabilities, which is recommended for\n",
      " |      an ensemble of well-calibrated classifiers.\n",
      " |  \n",
      " |  weights : array-like of shape (n_classifiers,), default=None\n",
      " |      Sequence of weights (`float` or `int`) to weight the occurrences of\n",
      " |      predicted class labels (`hard` voting) or class probabilities\n",
      " |      before averaging (`soft` voting). Uses uniform weights if `None`.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel for ``fit``.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  flatten_transform : bool, default=True\n",
      " |      Affects shape of transform output only when voting='soft'\n",
      " |      If voting='soft' and flatten_transform=True, transform method returns\n",
      " |      matrix with shape (n_samples, n_classifiers * n_classes). If\n",
      " |      flatten_transform=False, it returns\n",
      " |      (n_classifiers, n_samples, n_classes).\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      If True, the time elapsed while fitting will be printed as it\n",
      " |      is completed.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimators_ : list of classifiers\n",
      " |      The collection of fitted sub-estimators as defined in ``estimators``\n",
      " |      that are not 'drop'.\n",
      " |  \n",
      " |  named_estimators_ : :class:`~sklearn.utils.Bunch`\n",
      " |      Attribute to access any fitted sub-estimators by name.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  classes_ : array-like of shape (n_predictions,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  VotingRegressor: Prediction voting regressor.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> from sklearn.naive_bayes import GaussianNB\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
      " |  >>> clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
      " |  >>> clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
      " |  >>> clf3 = GaussianNB()\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      " |  >>> y = np.array([1, 1, 1, 2, 2, 2])\n",
      " |  >>> eclf1 = VotingClassifier(estimators=[\n",
      " |  ...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
      " |  >>> eclf1 = eclf1.fit(X, y)\n",
      " |  >>> print(eclf1.predict(X))\n",
      " |  [1 1 1 2 2 2]\n",
      " |  >>> np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
      " |  ...                eclf1.named_estimators_['lr'].predict(X))\n",
      " |  True\n",
      " |  >>> eclf2 = VotingClassifier(estimators=[\n",
      " |  ...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
      " |  ...         voting='soft')\n",
      " |  >>> eclf2 = eclf2.fit(X, y)\n",
      " |  >>> print(eclf2.predict(X))\n",
      " |  [1 1 1 2 2 2]\n",
      " |  >>> eclf3 = VotingClassifier(estimators=[\n",
      " |  ...        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
      " |  ...        voting='soft', weights=[2,1,1],\n",
      " |  ...        flatten_transform=True)\n",
      " |  >>> eclf3 = eclf3.fit(X, y)\n",
      " |  >>> print(eclf3.predict(X))\n",
      " |  [1 1 1 2 2 2]\n",
      " |  >>> print(eclf3.transform(X).shape)\n",
      " |  (6, 6)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      VotingClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      _BaseVoting\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.ensemble._base._BaseHeterogeneousEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.utils.metaestimators._BaseComposition\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimators, *, voting='hard', weights=None, n_jobs=None, flatten_transform=True, verbose=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the estimators.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted.\n",
      " |          Note that this is supported only if all underlying estimators\n",
      " |          support sample weights.\n",
      " |      \n",
      " |          .. versionadded:: 0.18\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      maj : array-like of shape (n_samples,)\n",
      " |          Predicted class labels.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Return class labels or probabilities for X for each estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      probabilities_or_labels\n",
      " |          If `voting='soft'` and `flatten_transform=True`:\n",
      " |              returns ndarray of shape (n_classifiers, n_samples *\n",
      " |              n_classes), being class probabilities calculated by each\n",
      " |              classifier.\n",
      " |          If `voting='soft' and `flatten_transform=False`:\n",
      " |              ndarray of shape (n_classifiers, n_samples, n_classes)\n",
      " |          If `voting='hard'`:\n",
      " |              ndarray of shape (n_samples, n_classifiers), being\n",
      " |              class labels predicted by each classifier.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      avg : array-like of shape (n_samples, n_classes)\n",
      " |          Weighted average probability for each class per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from _BaseVoting:\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,), default=None\n",
      " |          Target values.\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base._BaseHeterogeneousEnsemble:\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get the parameters of an estimator from the ensemble.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          Setting it to True gets the various classifiers and the parameters\n",
      " |          of the classifiers as well.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of an estimator from the ensemble.\n",
      " |      \n",
      " |      Valid parameter keys can be listed with `get_params()`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : keyword arguments\n",
      " |          Specific parameters using e.g.\n",
      " |          `set_params(parameter_name=new_value)`. In addition, to setting the\n",
      " |          parameters of the stacking estimator, the individual estimator of\n",
      " |          the stacking estimators can also be set, or can be removed by\n",
      " |          setting them to 'drop'.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base._BaseHeterogeneousEnsemble:\n",
      " |  \n",
      " |  named_estimators\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.utils.metaestimators._BaseComposition:\n",
      " |  \n",
      " |  __annotations__ = {'steps': typing.List[typing.Any]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn 99.33333333333333 %\n",
      "rf 92.44444444444444 %\n",
      "svc 98.66666666666667 %\n",
      "DT 67.33333333333333 %\n",
      "Lr 97.33333333333334 %\n"
     ]
    }
   ],
   "source": [
    "for est,name in zip(vclass.estimators_,vclass.estimators):\n",
    "    print(name[0],est.score(X2,y2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.33333333333333"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2,yPred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting classifier \n",
    "- It is an ensemble modeling technique which attempts to build a strong classifier from the number of weak classifiers\n",
    "\n",
    "**AdaBoost** \n",
    "- It was the first really successful boosting algorithm developed for the purpose of binary classification.\n",
    "- AdaBoost is short for Adaptive Boosting and is a very popular boosting technique which combines multiple “weak classifiers” into a single “strong classifier”.\n",
    "- Boosting in general is about building a model from the training data, then creating a second model that attempts to correct the errors from the first model. Models are added until the training set is predicted perfectly or a maximum number of models are added.\n",
    "- AdaBoost can be used for both classification & regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcls.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dcls.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DesicionTree -classifier -accuracy - 67.55555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"DesicionTree -classifier -accuracy -\",accuracy_score(y2,y)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "adcls=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adcls.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=adcls.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After -appling -Adaboosting classifier:  94.88888888888889 %\n"
     ]
    }
   ],
   "source": [
    "print(\"After -appling -Adaboosting classifier: \",accuracy_score(y2,yp)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rent</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>size_sqft</th>\n",
       "      <th>min_to_subway</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_age_yrs</th>\n",
       "      <th>no_fee</th>\n",
       "      <th>has_roofdeck</th>\n",
       "      <th>has_washer_dryer</th>\n",
       "      <th>has_doorman</th>\n",
       "      <th>has_elevator</th>\n",
       "      <th>has_dishwasher</th>\n",
       "      <th>has_patio</th>\n",
       "      <th>has_gym</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1545</td>\n",
       "      <td>2550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Upper East Side</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2472</td>\n",
       "      <td>11500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2919</td>\n",
       "      <td>4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>916</td>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2790</td>\n",
       "      <td>4795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>975</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3946</td>\n",
       "      <td>17500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4800</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Soho</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rental_id   rent  bedrooms  bathrooms  size_sqft  min_to_subway  floor  \\\n",
       "0       1545   2550       0.0          1        480              9    2.0   \n",
       "1       2472  11500       2.0          2       2000              4    1.0   \n",
       "2       2919   4500       1.0          1        916              2   51.0   \n",
       "3       2790   4795       1.0          1        975              3    8.0   \n",
       "4       3946  17500       2.0          2       4800              3    4.0   \n",
       "\n",
       "   building_age_yrs  no_fee  has_roofdeck  has_washer_dryer  has_doorman  \\\n",
       "0                17       1             1                 0            0   \n",
       "1                96       0             0                 0            0   \n",
       "2                29       0             1                 0            1   \n",
       "3                31       0             0                 0            1   \n",
       "4               136       0             0                 0            1   \n",
       "\n",
       "   has_elevator  has_dishwasher  has_patio  has_gym       neighborhood  \\\n",
       "0             1               1          0        1    Upper East Side   \n",
       "1             0               0          0        0  Greenwich Village   \n",
       "2             1               1          0        0            Midtown   \n",
       "3             1               1          0        1  Greenwich Village   \n",
       "4             1               1          0        1               Soho   \n",
       "\n",
       "     borough  \n",
       "0  Manhattan  \n",
       "1  Manhattan  \n",
       "2  Manhattan  \n",
       "3  Manhattan  \n",
       "4  Manhattan  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =pd.read_csv(\"https://raw.githubusercontent.com/LavanyaPolamarasetty/Datasets/master/Regression/manhattan_Housing.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3539, 18)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rent</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>size_sqft</th>\n",
       "      <th>min_to_subway</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_age_yrs</th>\n",
       "      <th>no_fee</th>\n",
       "      <th>has_roofdeck</th>\n",
       "      <th>has_washer_dryer</th>\n",
       "      <th>has_doorman</th>\n",
       "      <th>has_elevator</th>\n",
       "      <th>has_dishwasher</th>\n",
       "      <th>has_patio</th>\n",
       "      <th>has_gym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rental_id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.134347</td>\n",
       "      <td>-0.070290</td>\n",
       "      <td>-0.109414</td>\n",
       "      <td>-0.107711</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>-0.082586</td>\n",
       "      <td>0.028543</td>\n",
       "      <td>0.064919</td>\n",
       "      <td>-0.023335</td>\n",
       "      <td>-0.072738</td>\n",
       "      <td>-0.057786</td>\n",
       "      <td>-0.060152</td>\n",
       "      <td>-0.029615</td>\n",
       "      <td>-0.004253</td>\n",
       "      <td>-0.023457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent</th>\n",
       "      <td>-0.134347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638336</td>\n",
       "      <td>0.769474</td>\n",
       "      <td>0.857954</td>\n",
       "      <td>0.035164</td>\n",
       "      <td>0.215867</td>\n",
       "      <td>-0.128895</td>\n",
       "      <td>-0.101497</td>\n",
       "      <td>0.035165</td>\n",
       "      <td>0.053873</td>\n",
       "      <td>0.031302</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.052241</td>\n",
       "      <td>0.029302</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>-0.070290</td>\n",
       "      <td>0.638336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720885</td>\n",
       "      <td>0.771263</td>\n",
       "      <td>0.076543</td>\n",
       "      <td>0.043539</td>\n",
       "      <td>0.037228</td>\n",
       "      <td>-0.100352</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>-0.017331</td>\n",
       "      <td>-0.006771</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>-0.004112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>-0.109414</td>\n",
       "      <td>0.769474</td>\n",
       "      <td>0.720885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803627</td>\n",
       "      <td>0.086932</td>\n",
       "      <td>0.127969</td>\n",
       "      <td>-0.095421</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>0.025752</td>\n",
       "      <td>0.014745</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.042304</td>\n",
       "      <td>0.029739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_sqft</th>\n",
       "      <td>-0.107711</td>\n",
       "      <td>0.857954</td>\n",
       "      <td>0.771263</td>\n",
       "      <td>0.803627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039448</td>\n",
       "      <td>0.107186</td>\n",
       "      <td>0.014489</td>\n",
       "      <td>-0.141451</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.038263</td>\n",
       "      <td>0.026098</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>0.050364</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>0.029347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_to_subway</th>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.035164</td>\n",
       "      <td>0.076543</td>\n",
       "      <td>0.086932</td>\n",
       "      <td>0.039448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082445</td>\n",
       "      <td>-0.184682</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>-0.020693</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>-0.009012</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>-0.012244</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>-0.004315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor</th>\n",
       "      <td>-0.082586</td>\n",
       "      <td>0.215867</td>\n",
       "      <td>0.043539</td>\n",
       "      <td>0.127969</td>\n",
       "      <td>0.107186</td>\n",
       "      <td>0.082445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.389260</td>\n",
       "      <td>0.104317</td>\n",
       "      <td>0.056322</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>0.095963</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.059423</td>\n",
       "      <td>0.065410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_age_yrs</th>\n",
       "      <td>0.028543</td>\n",
       "      <td>-0.128895</td>\n",
       "      <td>0.037228</td>\n",
       "      <td>-0.095421</td>\n",
       "      <td>0.014489</td>\n",
       "      <td>-0.184682</td>\n",
       "      <td>-0.389260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221429</td>\n",
       "      <td>-0.041305</td>\n",
       "      <td>-0.030014</td>\n",
       "      <td>-0.047265</td>\n",
       "      <td>-0.060627</td>\n",
       "      <td>-0.027420</td>\n",
       "      <td>-0.050321</td>\n",
       "      <td>-0.063110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_fee</th>\n",
       "      <td>0.064919</td>\n",
       "      <td>-0.101497</td>\n",
       "      <td>-0.100352</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>-0.141451</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>0.104317</td>\n",
       "      <td>-0.221429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.095718</td>\n",
       "      <td>-0.070324</td>\n",
       "      <td>-0.182547</td>\n",
       "      <td>-0.161519</td>\n",
       "      <td>-0.078660</td>\n",
       "      <td>-0.049684</td>\n",
       "      <td>-0.101230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_roofdeck</th>\n",
       "      <td>-0.023335</td>\n",
       "      <td>0.035165</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>-0.020693</td>\n",
       "      <td>0.056322</td>\n",
       "      <td>-0.041305</td>\n",
       "      <td>-0.095718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.313459</td>\n",
       "      <td>0.489836</td>\n",
       "      <td>0.516534</td>\n",
       "      <td>0.331999</td>\n",
       "      <td>0.122568</td>\n",
       "      <td>0.561626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_washer_dryer</th>\n",
       "      <td>-0.072738</td>\n",
       "      <td>0.053873</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>0.025752</td>\n",
       "      <td>0.038263</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>-0.030014</td>\n",
       "      <td>-0.070324</td>\n",
       "      <td>0.313459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328291</td>\n",
       "      <td>0.379999</td>\n",
       "      <td>0.455166</td>\n",
       "      <td>0.140979</td>\n",
       "      <td>0.348433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_doorman</th>\n",
       "      <td>-0.057786</td>\n",
       "      <td>0.031302</td>\n",
       "      <td>-0.017331</td>\n",
       "      <td>0.014745</td>\n",
       "      <td>0.026098</td>\n",
       "      <td>-0.009012</td>\n",
       "      <td>0.095963</td>\n",
       "      <td>-0.047265</td>\n",
       "      <td>-0.182547</td>\n",
       "      <td>0.489836</td>\n",
       "      <td>0.328291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717929</td>\n",
       "      <td>0.343159</td>\n",
       "      <td>0.140968</td>\n",
       "      <td>0.633628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_elevator</th>\n",
       "      <td>-0.060152</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>-0.006771</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>-0.060627</td>\n",
       "      <td>-0.161519</td>\n",
       "      <td>0.516534</td>\n",
       "      <td>0.379999</td>\n",
       "      <td>0.717929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419812</td>\n",
       "      <td>0.134536</td>\n",
       "      <td>0.642099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_dishwasher</th>\n",
       "      <td>-0.029615</td>\n",
       "      <td>0.052241</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.050364</td>\n",
       "      <td>-0.012244</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>-0.027420</td>\n",
       "      <td>-0.078660</td>\n",
       "      <td>0.331999</td>\n",
       "      <td>0.455166</td>\n",
       "      <td>0.343159</td>\n",
       "      <td>0.419812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133127</td>\n",
       "      <td>0.342590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_patio</th>\n",
       "      <td>-0.004253</td>\n",
       "      <td>0.029302</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.042304</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.059423</td>\n",
       "      <td>-0.050321</td>\n",
       "      <td>-0.049684</td>\n",
       "      <td>0.122568</td>\n",
       "      <td>0.140979</td>\n",
       "      <td>0.140968</td>\n",
       "      <td>0.134536</td>\n",
       "      <td>0.133127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_gym</th>\n",
       "      <td>-0.023457</td>\n",
       "      <td>0.040609</td>\n",
       "      <td>-0.004112</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.029347</td>\n",
       "      <td>-0.004315</td>\n",
       "      <td>0.065410</td>\n",
       "      <td>-0.063110</td>\n",
       "      <td>-0.101230</td>\n",
       "      <td>0.561626</td>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.633628</td>\n",
       "      <td>0.642099</td>\n",
       "      <td>0.342590</td>\n",
       "      <td>0.123524</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rental_id      rent  bedrooms  bathrooms  size_sqft  \\\n",
       "rental_id          1.000000 -0.134347 -0.070290  -0.109414  -0.107711   \n",
       "rent              -0.134347  1.000000  0.638336   0.769474   0.857954   \n",
       "bedrooms          -0.070290  0.638336  1.000000   0.720885   0.771263   \n",
       "bathrooms         -0.109414  0.769474  0.720885   1.000000   0.803627   \n",
       "size_sqft         -0.107711  0.857954  0.771263   0.803627   1.000000   \n",
       "min_to_subway      0.009615  0.035164  0.076543   0.086932   0.039448   \n",
       "floor             -0.082586  0.215867  0.043539   0.127969   0.107186   \n",
       "building_age_yrs   0.028543 -0.128895  0.037228  -0.095421   0.014489   \n",
       "no_fee             0.064919 -0.101497 -0.100352  -0.062205  -0.141451   \n",
       "has_roofdeck      -0.023335  0.035165  0.002938   0.019556   0.024822   \n",
       "has_washer_dryer  -0.072738  0.053873  0.008721   0.025752   0.038263   \n",
       "has_doorman       -0.057786  0.031302 -0.017331   0.014745   0.026098   \n",
       "has_elevator      -0.060152  0.051860 -0.006771   0.021150   0.040916   \n",
       "has_dishwasher    -0.029615  0.052241  0.005467   0.038829   0.050364   \n",
       "has_patio         -0.004253  0.029302  0.003037   0.042304   0.021921   \n",
       "has_gym           -0.023457  0.040609 -0.004112   0.029739   0.029347   \n",
       "\n",
       "                  min_to_subway     floor  building_age_yrs    no_fee  \\\n",
       "rental_id              0.009615 -0.082586          0.028543  0.064919   \n",
       "rent                   0.035164  0.215867         -0.128895 -0.101497   \n",
       "bedrooms               0.076543  0.043539          0.037228 -0.100352   \n",
       "bathrooms              0.086932  0.127969         -0.095421 -0.062205   \n",
       "size_sqft              0.039448  0.107186          0.014489 -0.141451   \n",
       "min_to_subway          1.000000  0.082445         -0.184682  0.080088   \n",
       "floor                  0.082445  1.000000         -0.389260  0.104317   \n",
       "building_age_yrs      -0.184682 -0.389260          1.000000 -0.221429   \n",
       "no_fee                 0.080088  0.104317         -0.221429  1.000000   \n",
       "has_roofdeck          -0.020693  0.056322         -0.041305 -0.095718   \n",
       "has_washer_dryer      -0.001327  0.038870         -0.030014 -0.070324   \n",
       "has_doorman           -0.009012  0.095963         -0.047265 -0.182547   \n",
       "has_elevator          -0.000410  0.068917         -0.060627 -0.161519   \n",
       "has_dishwasher        -0.012244  0.002337         -0.027420 -0.078660   \n",
       "has_patio              0.001500  0.059423         -0.050321 -0.049684   \n",
       "has_gym               -0.004315  0.065410         -0.063110 -0.101230   \n",
       "\n",
       "                  has_roofdeck  has_washer_dryer  has_doorman  has_elevator  \\\n",
       "rental_id            -0.023335         -0.072738    -0.057786     -0.060152   \n",
       "rent                  0.035165          0.053873     0.031302      0.051860   \n",
       "bedrooms              0.002938          0.008721    -0.017331     -0.006771   \n",
       "bathrooms             0.019556          0.025752     0.014745      0.021150   \n",
       "size_sqft             0.024822          0.038263     0.026098      0.040916   \n",
       "min_to_subway        -0.020693         -0.001327    -0.009012     -0.000410   \n",
       "floor                 0.056322          0.038870     0.095963      0.068917   \n",
       "building_age_yrs     -0.041305         -0.030014    -0.047265     -0.060627   \n",
       "no_fee               -0.095718         -0.070324    -0.182547     -0.161519   \n",
       "has_roofdeck          1.000000          0.313459     0.489836      0.516534   \n",
       "has_washer_dryer      0.313459          1.000000     0.328291      0.379999   \n",
       "has_doorman           0.489836          0.328291     1.000000      0.717929   \n",
       "has_elevator          0.516534          0.379999     0.717929      1.000000   \n",
       "has_dishwasher        0.331999          0.455166     0.343159      0.419812   \n",
       "has_patio             0.122568          0.140979     0.140968      0.134536   \n",
       "has_gym               0.561626          0.348433     0.633628      0.642099   \n",
       "\n",
       "                  has_dishwasher  has_patio   has_gym  \n",
       "rental_id              -0.029615  -0.004253 -0.023457  \n",
       "rent                    0.052241   0.029302  0.040609  \n",
       "bedrooms                0.005467   0.003037 -0.004112  \n",
       "bathrooms               0.038829   0.042304  0.029739  \n",
       "size_sqft               0.050364   0.021921  0.029347  \n",
       "min_to_subway          -0.012244   0.001500 -0.004315  \n",
       "floor                   0.002337   0.059423  0.065410  \n",
       "building_age_yrs       -0.027420  -0.050321 -0.063110  \n",
       "no_fee                 -0.078660  -0.049684 -0.101230  \n",
       "has_roofdeck            0.331999   0.122568  0.561626  \n",
       "has_washer_dryer        0.455166   0.140979  0.348433  \n",
       "has_doorman             0.343159   0.140968  0.633628  \n",
       "has_elevator            0.419812   0.134536  0.642099  \n",
       "has_dishwasher          1.000000   0.133127  0.342590  \n",
       "has_patio               0.133127   1.000000  0.123524  \n",
       "has_gym                 0.342590   0.123524  1.000000  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =data[[\"size_sqft\",\"bathrooms\",\"bedrooms\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =data[\"rent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt,Xtest,yt,ytest =train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "adreg=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=5))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adreg.fit(Xt,yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=adreg.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.24236743049667"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(ytest,yp)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreg=DecisionTreeRegressor(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dreg.fit(Xt,yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dreg.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.40130243755385"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(ytest,y)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s1 -A\n",
    "S2 -A\n",
    "S3 -B\n",
    "S4 -B\n",
    "\n",
    "A\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
